q()
q()
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
library(base)
install.packages("ggplot2")
library(ggplot2)
install.packages("XML")
library(XML)
install.packages("xlsx")
library(xlsx)
install.packages("jsonlite")
library(jsonlite)
install.packages("httr")
library(httr)
install.packages("data.table")
library(data.table)
install.packages("DBI")
library(DBI)
install.packages("datasets")
library(datasets)
# MySQL Interface - http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL
#install.packages("RMySQL")
#library(RMySQL)
install.packages("jpeg")
library(jpeg)
install.packages("graphics")
library(graphics)
install.packages("grDevices")
library(grDevices)
install.packages("lattice")
library(lattice)
install.packages("Matrix")
library(Matrix)
install.packages("plyr")
library(plyr)
install.packages("RCurl")
library(RCurl)
install.packages("RSQLite")
library(RSQLite)
install.packages("RSQLite.extfuns")
library(RSQLite.extfuns)
install.packages("tools")
library(tools)
install.packages("base")
install.packages("datasets")
install.packages("graphics")
install.packages("grDevices")
install.packages("tools")
install.packages("base")
install.packages("graphics")
install.packages("grDevices")
install.packages("datasets")
install.packages("base")
install.packages("grDevices")
install.packages("datasets")
install.packages("graphics")
install.packages("grDevices")
install.packages("datasets")
install.packages("grDevices")
install.packages("datasets")
library(caret)
library(kernlab)
path
library(kernlab)
install.packages("kernlab")
library(kernlab)
ver
version
raw_training <- read.csv('pml-training.csv')
version
install.packages("kernlab")
install.packages("kernlab")
library(kernlab)
raw_training <- read.csv('pml-training.csv')
.libPaths()
setwd("D:\Dropbox\Gal_Private\Courses\Data Science Specialization\6. Practical Machine Learning\Projects\DataScience-ML-Project-master")
setwd("D:\\Dropbox\\Gal_Private\\Courses\\Data Science Specialization\\6. Practical Machine Learning\\Projects\\DataScience-ML-Project-master")
raw_training <- read.csv('pml-training.csv')
raw_testing <- read.csv('pml-testing.csv')
set.seed(1234)
trainingIndex <- createDataPartition(raw_training$classe, list=FALSE, p=.9)
training = raw_training[trainingIndex,]
testing = raw_training[-trainingIndex,]
nzv <- nearZeroVar(training)
training <- training[-nzv]
testing <- testing[-nzv]
raw_testing <- raw_testing[-nzv]
training <- training[-5]
testing <- testing[-5]
raw_testing <- raw_testing[-5]
num_features_idx = which(lapply(training,class) %in% c('numeric')  )
preModel <- preProcess(training[,num_features_idx], method=c('knnImpute'))
ptraining <- cbind(training$classe, predict(preModel, training[,num_features_idx]))
ptesting <- cbind(testing$classe, predict(preModel, testing[,num_features_idx]))
prtesting <- cbind(raw_testing$classe, predict(preModel, raw_testing[,num_features_idx]))
names(ptraining)[1] <- 'classe'
names(ptesting)[1] <- 'classe'
#ksvm_model  <- ksvm(classe ~ ., ptraining)
ptraining[is.na(ptraining)] <- 0
ptesting[is.na(ptesting)] <- 0
prtesting[is.na(prtesting)] <- 0
rf_model  <- randomForest(classe ~ ., ptraining)
#gbm_model  <- gbm(classe ~ ., data=ptraining)
ksvm_model  <- ksvm(classe ~ ., data=ptraining)
#rpart_model  <- train(classe ~ ., ptraining, method='rf')
#rf_model  <- train(classe ~ ., training_sub, method='rf')
#lda_model  <- train(classe ~ ., training_sub, method='lda')
#gbm_model  <- train(classe ~ ., training_sub, method='gbm')
#lasso_model  <- train(classe ~ ., training_sub, method='lasso')
testing_pred <- predict(rf_model, ptesting)
print(table(testing_pred, ptesting$classe))
print(mean(testing_pred == ptesting$classe))
print(mean(testing_pred == ptesting$classe))
setwd("D:\\Dropbox\\Gal_Private\\Courses\\Data Science Specialization\\6. Practical Machine Learning\\Projects\\DataScience-ML-Project-master")
library(caret)
install.packages("kernlab")
install.packages("kernlab")
library(kernlab)
raw_training <- read.csv('pml-training.csv')
raw_testing <- read.csv('pml-testing.csv')
set.seed(1234)
trainingIndex <- createDataPartition(raw_training$classe, list=FALSE, p=.9)
training = raw_training[trainingIndex,]
testing = raw_training[-trainingIndex,]
nzv <- nearZeroVar(training)
training <- training[-nzv]
testing <- testing[-nzv]
raw_testing <- raw_testing[-nzv]
training <- training[-5]
testing <- testing[-5]
raw_testing <- raw_testing[-5]
num_features_idx = which(lapply(training,class) %in% c('numeric')  )
preModel <- preProcess(training[,num_features_idx], method=c('knnImpute'))
ptraining <- cbind(training$classe, predict(preModel, training[,num_features_idx]))
ptesting <- cbind(testing$classe, predict(preModel, testing[,num_features_idx]))
prtesting <- cbind(raw_testing$classe, predict(preModel, raw_testing[,num_features_idx]))
names(ptraining)[1] <- 'classe'
names(ptesting)[1] <- 'classe'
#ksvm_model  <- ksvm(classe ~ ., ptraining)
ptraining[is.na(ptraining)] <- 0
ptesting[is.na(ptesting)] <- 0
prtesting[is.na(prtesting)] <- 0
rf_model  <- randomForest(classe ~ ., ptraining)
#gbm_model  <- gbm(classe ~ ., data=ptraining)
ksvm_model  <- ksvm(classe ~ ., data=ptraining)
#rpart_model  <- train(classe ~ ., ptraining, method='rf')
#rf_model  <- train(classe ~ ., training_sub, method='rf')
#lda_model  <- train(classe ~ ., training_sub, method='lda')
#gbm_model  <- train(classe ~ ., training_sub, method='gbm')
#lasso_model  <- train(classe ~ ., training_sub, method='lasso')
testing_pred <- predict(rf_model, ptesting)
print(table(testing_pred, ptesting$classe))
print(mean(testing_pred == ptesting$classe))
testing_pred <- predict(rf_model, ptraining)
rf_model  <- randomForest(classe ~ ., ptraining)
install.packages("randomforest")
install.packages("randomForest")
rf_model  <- randomForest(classe ~ ., ptraining)
install.packages("randomForest")
install.packages("kernlab")
install.packages("kernlab")
library(caret)
library(kernlab)
library(randomForest)
setwd("D:\\Dropbox\\Gal_Private\\Courses\\Data Science Specialization\\6. Practical Machine Learning\\Projects\\DataScience-ML-Project-master")
install.packages("randomForest")
install.packages("kernlab")
library(caret)
library(kernlab)
library(randomForest)
raw_training <- read.csv('pml-training.csv')
raw_testing <- read.csv('pml-testing.csv')
set.seed(1234)
trainingIndex <- createDataPartition(raw_training$classe, list=FALSE, p=.9)
training = raw_training[trainingIndex,]
testing = raw_training[-trainingIndex,]
nzv <- nearZeroVar(training)
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
install.packages("base")
library(base)
install.packages("ggplot2")
library(ggplot2)
install.packages("XML")
library(XML)
install.packages("xlsx")
library(xlsx)
install.packages("jsonlite")
library(jsonlite)
install.packages("httr")
library(httr)
install.packages("data.table")
library(data.table)
install.packages("DBI")
library(DBI)
install.packages("datasets")
library(datasets)
# MySQL Interface - http://biostat.mc.vanderbilt.edu/wiki/Main/RMySQL
#install.packages("RMySQL")
#library(RMySQL)
install.packages("jpeg")
library(jpeg)
install.packages("graphics")
library(graphics)
install.packages("grDevices")
library(grDevices)
install.packages("lattice")
library(lattice)
install.packages("datasets")
install.packages("graphics")
install.packages("lattice")
install.packages("grDevices")
install.packages("grDevices")
install.packages("Matrix")
library(Matrix)
install.packages("plyr")
install.packages("plyr")
library(plyr)
install.packages("RCurl")
library(RCurl)
install.packages("RSQLite")
library(RSQLite)
install.packages("RSQLite.extfuns")
library(RSQLite.extfuns)
install.packages("tools")
library(tools)
install.packages("tools")
set.seed(1234)
trainingIndex <- createDataPartition(raw_training$classe, list=FALSE, p=.9)
training = raw_training[trainingIndex,]
testing = raw_training[-trainingIndex,]
install.packages("createDataPartition")
library(createDataPartition)
library(createDataPartition)
install.packages("createDataPartition")
library(caret)
library(kernlab)
library(randomForest)
library(createDataPartition)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
sum(w*x)/sum(w)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mew <- c(1.077, 0.300, 0.0025, 0.1471)
for (each in mew){
total <- 0
#print(each)
#print(x[i])
#print(w[i])
for (i in 1:4){
total = total + w[i]*(x[i]-each)**2
}
print(total)
}
w(x-mew)**2
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
weighted.mean(x, w) # 0.1471
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit<- lm( y ~ x - 1 )
summary(fit) # 0.8263
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit<- lm( y ~ x - 1 )
summary(fit) # 0.8263
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit) # -5.3445
data(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit) # -5.3445
n<-100; t<-rep(c(0,1), c(n/2, n/2)); x<-c(runif(n/2));
beta0<-0; beta1<-2; tau<-1; sigma<-.2;
y<-beta0+x*beta1+t*tau+rnotm(n, sd = sigma)
y<-beta0+x*beta1+t*tau+rnorm(n, sd = sigma)
plot(x,y,type="n", frame="FALSE")
plot(x,y,type="n", frame=FALSE)
n<-100; t<-rep(c(0,1), c(n/2, n/2)); x<-c(runif(n/2));
beta0<-0; beta1<-2; tau<-1; sigma<-.2;
y<-beta0+x*beta1+t*tau+rnorm(n, sd = sigma)
plot(x,y,type="n", frame=FALSE)
n<-100; t<-rep(c(0,1), c(n/2, n/2)); x<-c(runif(n/2), runif(n/2));
beta0<-0; beta1<-2; tau<-1; sigma<-.2;
y<-beta0+x*beta1+t*tau+rnorm(n, sd = sigma)
plot(x,y,type="n", frame=FALSE)
abline(lm(y~x), lwd=2)
abline(lm(y~x), lwd=2)
abline(h=mean(y[1:(n/2)]), lwd=3)
abline(h=mean(y[(n/2 + 1):n]), lwd=3)
fit<=lm(y~x+t)
abline(coef(fit)[1], coef(fit)[2], lwd=3)
abline(coef(fit)[1], coef(fit)[3], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
n<-100; t<-rep(c(0,1), c(n/2, n/2)); x<-c(runif(n/2), runif(n/2));
beta0<-0; beta1<-2; tau<-1; sigma<-.2;
y<-beta0+x*beta1+t*tau+rnorm(n, sd = sigma)
plot(x,y,type="n", frame=FALSE)
abline(lm(y~x), lwd=2)
abline(h=mean(y[1:(n/2)]), lwd=3)
abline(h=mean(y[(n/2 + 1):n]), lwd=3)
fit<=lm(y~x+t)
abline(coef(fit)[1], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
n<-100; t<-rep(c(0,1), c(n/2, n/2)); x<-c(runif(n/2), runif(n/2));
n<-100; t<-rep(c(0,1), c(n/2, n/2)); x<-c(runif(n/2), runif(n/2));
beta0<-0; beta1<-2; tau<-1; sigma<-.2;
y<-beta0+x*beta1+t*tau+rnorm(n, sd = sigma)
plot(x,y,type="n", frame=FALSE)
abline(lm(y~x), lwd=2)
abline(h=mean(y[1:(n/2)]), lwd=3)
abline(h=mean(y[(n/2 + 1):n]), lwd=3)
fit<=lm(y~x+t)
abline(coef(fit)[1], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
fit<=lm(y~x + t)
abline(coef(fit)[1], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
abline(coef(fit)[1], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
abline(coef(fit)[1], coef(fit)[2], lwd=3)
abline(coef(fit)[1] + coef(fit)[3], coef(fit)[2], lwd=3)
data(swiss)
library(tseries, quietly = T)
install.packages(tseries)
install.packages("tseries")
library(tseries, quietly = T)
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
lm.influence(fit)$hat
hatvalues(fit)
?hatvalue
?hatvalues
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
lm.influence(fit)$hat
dfbetas(fit)
?dfbetas
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
lm.influence(fit)$hat
dfbetas(fit)
data(mtcars)
fit1 <- lm(mpg~factor(cyl) + wt, data=mtcars)
fit2 <- update(fit1, mpg~factor(cyl) + wt + wt*factor(cyl))
summary(fit1)
summary(fit2)
compare <- anova(fit1, fit2)
compare$Pr
library(knitr)
data(mtcars)
opts_chunk$set(echo = FALSE)
opts_chunk$set(fig.width = 5)
opts_chunk
opts_chunk$set()
opts_chunk$set(echo
=FALSE)
mtcars
install.packages("UsingR")
library(UsingR)
data(galton)
par(mfrow=c(1,2))
hist(galton$child, col="blue", breaks=100)
hist(galton$parent, col="blue", breaks=100)
install.packages("UsingR")
library(UsingR)
data(galton)
par(mfrow=c(1,2))
hist(galton$child, col="blue", breaks=100)
hist(galton$parent, col="blue", breaks=100)
install.packages("UsingR")
head(mtcars)
# Setting the working directory to the csv location
setwd("C:\\Users\\Gal\\Documents\\GitHub\\RepData_PeerAssessment1")
# Setting the working directory to the csv location
setwd("C:\\Users\\Gal\\Documents\\GitHub\\RepData_PeerAssessment2")
# Unzipping the file (if not unzipped already)
if(!file.exists("StormData.csv")) {
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",temp)
unzip(temp)
unlink(temp)
}
# Read the CSV file
stormData <- read.csv("StormData.csv")
```
```{r}
summary(cars)
```
stormData
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",temp)
names(stormData)
names(stormData)
setwd("C:\\Users\\Gal\\Documents\\GitHub\\RepData_PeerAssessment2")
# Unzipping the file (if not unzipped already)
#if(!file.exists("StormData.csv")) {
#       temp <- tempfile()
#        download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",temp)
#        unzip(temp)
#        unlink(temp)
#}
if(!file.exists("StormData.csv"))
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", destfile="StormData.csv")
stormData = read.csv("StormData.csv")
# Read the CSV file
stormData <- read.csv("StormData.csv")
names(stormData)
```
```{r}
names(stormData)
stormData <- read.csv("StormData.csv", Cache=TRUE)
head(stormData)
head(stormData, n=2)
tail(stormData, n=2)
names(stormData)
dim(stormData)
```{r}
cache=TRUE
if(!file.exists("StormData.csv")) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", destfile = "StormData.csv")
}
```
Read the CSV file
```{r}
#stormData <- read.csv("StormData.csv")
```
```{r}
names(stormData)
```
```{r}
dim(stormData)
```
